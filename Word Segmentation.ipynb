{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e6cfbb5",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4d79c05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for installing UrduHack\n",
    "# !pip install urduhack[tf]\n",
    "# !pip install nltk\n",
    "import urduhack\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd32767",
   "metadata": {},
   "source": [
    "# Dictionary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4d6015",
   "metadata": {},
   "source": [
    "Generic Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fc78b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('Dictionary.txt', 'rt', encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    passage = list(reader)\n",
    "    \n",
    "Dictionary=[]\n",
    "for i in passage:\n",
    "    for j in i:\n",
    "        Dictionary.append(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3036802",
   "metadata": {},
   "source": [
    "Urdu Date Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7489d064",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dates.txt', 'rt', encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    passage = list(reader)\n",
    "    \n",
    "Dictionary1=[]\n",
    "for i in passage:\n",
    "    for j in i:\n",
    "        Dictionary1.append(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f60192f",
   "metadata": {},
   "source": [
    "Urdu Bigram words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a1dc139",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bigram_words.txt', 'rt', encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    passage = list(reader)\n",
    "    \n",
    "Dictionary2=[]\n",
    "for i in passage:\n",
    "    for j in i:\n",
    "        Dictionary2.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0175983b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753ef408",
   "metadata": {},
   "source": [
    "Urdu Places Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54575174",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('locations.txt', 'rt', encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    passage = list(reader)\n",
    "    \n",
    "Dictionary3=[]\n",
    "for i in passage:\n",
    "    for j in i:\n",
    "        Dictionary3.append(j)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2ed986",
   "metadata": {},
   "source": [
    "Urdu organization words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30ed917f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('organizations.txt', 'rt', encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    passage = list(reader)\n",
    "    \n",
    "Dictionary4=[]\n",
    "for i in passage:\n",
    "    for j in i:\n",
    "        Dictionary4.append(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd5eeaa",
   "metadata": {},
   "source": [
    "Urdu Random Persons Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "943f7066",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('persons.txt', 'rt', encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    passage = list(reader)\n",
    "    \n",
    "Dictionary5=[]\n",
    "for i in passage:\n",
    "    for j in i:\n",
    "        Dictionary5.append(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bccb60",
   "metadata": {},
   "source": [
    "Combined Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e127c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154781\n",
      "55\n",
      "84\n",
      "2426\n",
      "1064\n",
      "3348\n"
     ]
    }
   ],
   "source": [
    "print(len(Dictionary))\n",
    "print(len(Dictionary1))\n",
    "print(len(Dictionary2))\n",
    "print(len(Dictionary3))\n",
    "print(len(Dictionary4))\n",
    "print(len(Dictionary5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b44f169",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dictionary.extend(Dictionary1)\n",
    "Dictionary.extend(Dictionary2)\n",
    "Dictionary.extend(Dictionary3)\n",
    "Dictionary.extend(Dictionary4)\n",
    "Dictionary.extend(Dictionary5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58098ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161758"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7943f3",
   "metadata": {},
   "source": [
    "# Preprocessing on dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82425d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = lambda x: x.replace('_', ' ')\n",
    "updated_list = list(map(converter, Dictionary)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "718ab568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161758"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(updated_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4606f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dictionary = sorted(updated_list, key=len, reverse=True)\n",
    "\n",
    "dic = np.array(Dictionary)\n",
    "dic, counts = np.unique(dic, return_counts=True)\n",
    "\n",
    "def merge(list1, list2):\n",
    "     \n",
    "    merged_list = [(list1[i], list2[i]) for i in range(0, len(list1))]\n",
    "    return merged_list\n",
    "\n",
    "tup=merge(dic, counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c452e140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158396"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2553a5",
   "metadata": {},
   "source": [
    "# Word Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4cae4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word_test.txt', 'rt', encoding=\"utf-8\") as f:\n",
    "    text3 = csv.reader(f)\n",
    "    unsegmented_words = list(text3)\n",
    "# unsegmented_words[0][0]\n",
    "\n",
    "\n",
    "with open('word-segmented.txt', 'rt', encoding=\"utf-8\") as f:\n",
    "    text4 = csv.reader(f)\n",
    "    words_test_case = list(text4)\n",
    "    \n",
    "# with open('segmented.txt', 'rt' , encoding=\"utf8\") as file:\n",
    "#     test_of_words = file.read(f)\n",
    "#     words = contents.split()\n",
    "#     file.close()\n",
    "# words = [word.strip() for word in words]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12e93f5",
   "metadata": {},
   "source": [
    "# Word Segmentation function 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ad90861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alphabet_parser(var1):\n",
    "    test_list=[]\n",
    "    for i in var1:\n",
    "        test_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cb4f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_exist=[]\n",
    "temp=\"\"\n",
    "size=max(len(j) for j in dic)\n",
    "def word_segmentation(size,dic,var1):\n",
    "    for k in reversed(range(size)):\n",
    "        dummy=var1[:k]\n",
    "        if dummy in dic:\n",
    "            if len(dummy)== k :\n",
    "                word_exist.append(dummy)\n",
    "                word_len=len(dummy)  \n",
    "                dummy=\"\"\n",
    "                var1=var1[word_len:]\n",
    "                break\n",
    "    return word_exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08962a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmented Words:\n",
      "\n",
      "['تجربہ', 'آفس', 'غورطلب', 'توشہ', 'تفصیلات', 'جج', 'یاد', 'سابق', 'مفتاح', 'سابق', 'وزیرداخلہ', 'اے', 'قبل', 'ایازصادق']\n",
      "\n",
      "\n",
      "Segmented Words String:\n",
      "\n",
      "['تجربہ آفس غورطلب توشہ تفصیلات جج یاد سابق مفتاح سابق وزیرداخلہ اے قبل ایازصادق']\n"
     ]
    }
   ],
   "source": [
    "words=[]\n",
    "for i in range(len(unsegmented_words)):\n",
    "    sentence=unsegmented_words[i][0]\n",
    "    res=word_segmentation(25, dic,sentence)\n",
    "    \n",
    "print(\"Segmented Words:\\n\")\n",
    "print(res)\n",
    "words.append(\" \".join(res))\n",
    "print(\"\\n\")\n",
    "print(\"Segmented Words String:\\n\")\n",
    "print(words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e104ce",
   "metadata": {},
   "source": [
    "# Word function test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d8fabb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=words_test_case[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea0327bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(res,test):\n",
    "    yes=0\n",
    "    no=0\n",
    "    for i,val in enumerate(res):\n",
    "        if val in test[i]:\n",
    "            yes=yes+1\n",
    "        else:\n",
    "            no=no+1\n",
    "    acc=(yes/len(res))*100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9720b5",
   "metadata": {},
   "source": [
    "# Word Segmentation Function 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11b74395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximum_length_match(var, size,dic):\n",
    "    word_lis = []\n",
    "    while var:\n",
    "        for i in reversed(range(1,size)):\n",
    "            if len(var) >= i :\n",
    "                if var[-i:] in dic:\n",
    "                    word_lis.append(var[-i:])\n",
    "                    var = var[:-i]\n",
    "                    break\n",
    "        else:\n",
    "            word_lis.append(var[-1])\n",
    "            var = var[:-1]\n",
    "    return word_lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1da55b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=[]\n",
    "size=max(len(j) for j in dic)\n",
    "for i in range(len(unsegmented_words)):\n",
    "    sentence=unsegmented_words[i][0]\n",
    "    res=maximum_length_match(sentence, 25,dic)\n",
    "    res.reverse()\n",
    "    output.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620a77d7",
   "metadata": {},
   "source": [
    "# Word Function Test Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4e5dde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word-segmented.txt', 'rt' , encoding=\"utf8\") as file:\n",
    "    contents = file.read()\n",
    "    words = contents.split()\n",
    "    file.close()\n",
    "acc_words = [word.strip() for word in words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ccb1e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_words=acc_words[:len(output[0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f73e9441",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=evaluate(output[0],acc_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "691b661f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Segmentation output:\n",
      "['تجربہ کار ہندوستانی آف سپنر روی چند رن ای شون نے آئن دہ ایشیاء کپ 2 0 2 3 ء کی غیر یقینی قسمت پر اپنی رائے کااظہار کیاہے جو پاکستان میں ہونے جارہاہے اپنے یوٹیوب چینل پر بات کرتے ہوئے روی چند رن ای شون نے کہاکہ اگر پڑوسی ملک بھارت ایشیا کپ 2 0 2 3 ء میں شرکت کرنا چاہتاہے تو مقام تبدیل کردینا چاہیے']\n",
      "\n",
      "\n",
      "provided test case:\n",
      "['تجربہ کار ہندوستانی آف سپنر روی چندرن ایشون نے آئندہ ایشیاء کپ 2023ء کی غیر یقینی قسمت پر اپنی رائے کا اظہار کیا ہے، جو پاکستان میں ہونے جا رہا ہے۔ اپنے یوٹیوب چینل پر بات کرتے ہوئے روی چندرن ایشون نے کہا کہ اگر پڑوسی ملک بھارت ایشیا کپ 2023ء میں شرکت کرنا چاہتا ہے تو مقام تبدیل کر دینا چاہیے۔']\n"
     ]
    }
   ],
   "source": [
    "output_string=[]\n",
    "output_string.append(\" \".join(output[0]))\n",
    "print(\"Word Segmentation output:\")\n",
    "print(output_string)\n",
    "print(\"\\n\")\n",
    "print(\"provided test case:\")\n",
    "print(words_test_case[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d67c874",
   "metadata": {},
   "source": [
    "# Sentence Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67a4fd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sent-segmented.txt', 'rt', encoding=\"utf-8\") as f:\n",
    "    text1 = csv.reader(f)\n",
    "    test_case = list(text1)\n",
    "test_case=test_case[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9beebca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'عقل خان کے مطابق اس خوبصورت چراگاہ کو کنڈیل شئی بانال کہا جاتا ہے۔ کنڈیل شئی بانال کے اس خوبصورت میدان کو اگر سویٹزرلینڈ کے کسی ہرے بھرے میدانی علاقے سے تشبیہہ دی جائے تو کچھ غلط نہیں ہوگا۔ میدان میں داخل ہوتے ہی کچھ دیر آرام کرنے کی میری خواہش پر سب نے لبیک کہا۔ ایسا لگا جیسے ان کی دل کی بات میرے لبوں سے ادا ہوئی ہو۔'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a61e33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_point=\"۔\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1686717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sent-test.txt', 'rt', encoding=\"utf-8\") as f:\n",
    "    text2 = csv.reader(f)\n",
    "    unsegmented = list(text2)\n",
    "unsegmented=unsegmented[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a67fe0c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'عقل خان کے مطابق اس خوبصورت چراگاہ کو کنڈیل شئی بانال کہا جاتا ہے کنڈیل شئی بانال کے اس خوبصورت میدان کو اگر سویٹزرلینڈ کے کسی ہرے بھرے میدانی علاقے سے تشبیہہ دی جائے تو کچھ غلط نہیں ہوگا میدان میں داخل ہوتے ہی کچھ دیر آرام کرنے کی میری خواہش پر سب نے لبیک کہا ایسا لگا جیسے ان کی دل کی بات میرے لبوں سے ادا ہوئی ہو۔'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsegmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc8812c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"urdu-to-roman-stop-words.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43ecc87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=df['urdu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "34459149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'آؤ'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d4b842c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimized_naive(txt,wrd):\n",
    "    lt=len(txt)\n",
    "    lw=len(wrd)\n",
    "    for i in range(lt-lw+1):\n",
    "        if txt[i:i+lw]==wrd:\n",
    "            return i\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7989a49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list=[]\n",
    "stop_words_list=[]\n",
    "for i in stopwords:\n",
    "#     print(i)\n",
    "    word_ind=optimized_naive(unsegmented,i)\n",
    "    if(word_ind):\n",
    "        index_list.append(word_ind)\n",
    "        stop_words_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c02b43e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "possibilities are that text can be segmented after word اب which is at index 13\n"
     ]
    }
   ],
   "source": [
    "print(\"possibilities are that text can be segmented after word\",stop_words_list[0],\"which is at index\",index_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "733bfb09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['عقل خان کے مطابق اس خوبصورت چراگاہ کو کنڈیل شئی بانال کہا جاتا ہے',\n",
       " 'کنڈیل شئی بانال کے اس خوبصورت میدان کو اگر سویٹزرلینڈ کے کسی ہرے بھرے میدانی علاقے سے تشبیہہ دی جائے تو کچھ غلط نہیں ہوگا میدان میں داخل ہوتے ہی کچھ دیر آرام کرنے کی میری خواہش پر سب نے لبیک کہا ایسا لگا جیسے ان کی دل کی بات میرے لبوں سے ادا ہوئی ہو۔']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urduhack\n",
    "from urduhack.tokenization import sentence_tokenizer\n",
    "sentences = sentence_tokenizer(unsegmented)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a32c91a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.08823529411764706\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(output[0], acc_words)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e2b2b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
